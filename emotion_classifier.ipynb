{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader # for the dataloader\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe into dictionary of text and labels\n",
    "def reader(df):\n",
    "    texts = df['text'].values.tolist()\n",
    "    labels = df['label'].values.tolist()\n",
    "\n",
    "    return {'texts':texts, 'labels':labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/emotionlabeled_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "class OlidDataset(Dataset):\n",
    "  def __init__(self, tokenizer, input_set):\n",
    "    # input_set: dictionary version of the df\n",
    "    self.texts = input_set['texts']\n",
    "    self.labels = input_set['labels']\n",
    "    self.tokenizer = tokenizer\n",
    "\n",
    "  def collate_fn(self, batch):\n",
    "    texts = []\n",
    "    labels = []\n",
    "\n",
    "    for b in batch:\n",
    "      texts.append(str(b['text']))\n",
    "      labels.append(b['label'])\n",
    "\n",
    "    print(texts)\n",
    "    print(labels)\n",
    "    encodings = self.tokenizer(\n",
    "      texts,                        # what to encode\n",
    "      return_tensors = 'pt',        # return pytorch tensors\n",
    "      add_special_tokens = True,    # incld tokens like [SEP], [CLS]\n",
    "      padding = \"max_length\",       # pad to max sentence length\n",
    "      truncation = True,            # truncate if too long\n",
    "      max_length= 128)              \n",
    "\n",
    "    encodings['labels'] = torch.tensor(labels)\n",
    "    return encodings\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.texts)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    item = {'text': self.texts[idx], 'label': self.labels[idx]}\n",
    "\n",
    "    return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "def train_model():\n",
    "    optimizer = 'AdamW'\n",
    "    learning_rate = 1.35e-04\n",
    "    epochs = 1\n",
    "    \n",
    "    model_args = ClassificationArgs(num_train_epochs=epochs, \n",
    "                                          no_save=True, \n",
    "                                          no_cache=True, \n",
    "                                          overwrite_output_dir=True,\n",
    "                                          learning_rate=learning_rate,\n",
    "                                          optimizer=optimizer)\n",
    "\n",
    "    model = ClassificationModel(model_type=\"xlmroberta\", \n",
    "                              model_name=\"xlm-roberta-base\", \n",
    "                              args = model_args, \n",
    "                              num_labels=4, \n",
    "                              use_cuda=cuda_available)\n",
    "    \n",
    "    print(model)\n",
    "    model.train_model(df_train[['text', 'labels']])\n",
    "\n",
    "    print('model train finished')\n",
    "    # Validation Set (Internal)\n",
    "    y_pred, _ = model.predict(df_val.text.tolist())\n",
    "    y_true = df_val['labels']\n",
    "    print(\"Classification metrics for validation set\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    # Test Set (Internal)\n",
    "    y_pred, _ = model.predict(df_test.text.tolist())\n",
    "    y_true = df_test['labels']\n",
    "    print(\"Classification metrics for test set\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    # # Test Set (External)\n",
    "    # y_pred, _ = model.predict(df_submission.text.tolist()) \n",
    "    # labels2file([[k] for k in y_pred], 'task1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<simpletransformers.classification.classification_model.ClassificationModel object at 0x7ff7b17299e8>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b48ef48160437ba8cb5d625453db60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicialawjy/Desktop/multilingual-psychotherapy-chatbot/satbot/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55bcaf9f6fe440586a5a0c4464c9bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497a1a9369364dbea08d8d2c6cf0c7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 1:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model train finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e880f10a1c24ab6a48de50c70a96950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c328b271cfe4ae795ca2b6fac78d48d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification metrics for validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.40      1.00      0.57         2\n",
      "\n",
      "    accuracy                           0.40         5\n",
      "   macro avg       0.13      0.33      0.19         5\n",
      "weighted avg       0.16      0.40      0.23         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicialawjy/Desktop/multilingual-psychotherapy-chatbot/satbot/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/alicialawjy/Desktop/multilingual-psychotherapy-chatbot/satbot/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/alicialawjy/Desktop/multilingual-psychotherapy-chatbot/satbot/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77d68565d33466b8688110c335abf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffae26dd768b4c78b3f2a861315b4040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification metrics for test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.20      1.00      0.33         1\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.20         5\n",
      "   macro avg       0.07      0.33      0.11         5\n",
      "weighted avg       0.04      0.20      0.07         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicialawjy/Desktop/multilingual-psychotherapy-chatbot/satbot/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/alicialawjy/Desktop/multilingual-psychotherapy-chatbot/satbot/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/alicialawjy/Desktop/multilingual-psychotherapy-chatbot/satbot/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "GPU = True\n",
    "\n",
    "if GPU:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "df_train = pd.read_csv('data/emotionlabeled_train.csv', index_col=0).head(10)\n",
    "df_val = pd.read_csv('data/emotionlabeled_val.csv', index_col=0).head(5)\n",
    "df_test = pd.read_csv('data/emotionlabeled_test.csv', index_col=0).head(5)\n",
    "\n",
    "# print(df_train[['text', 'labels']])\n",
    "# col_names = df_test.columns\n",
    "\n",
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6affe5b8c4f287722cc202c497c24ade3dd225e8a3881670ad8782202279ca81"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 ('satbot': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

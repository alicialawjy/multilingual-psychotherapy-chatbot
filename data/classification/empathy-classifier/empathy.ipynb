{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EmpatheticPersonas Empathy (Labelled) Dataset (1100 Instances)\n",
    "(Script used to clean and split the 1100 EmpatheticPersonas dataset labelled for empathy, to aid the training of an empathetic classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "EP_EN = pd.read_csv('EN_labelled/EP_EN_full.csv')\n",
    "EP_ZH = pd.read_csv('ZH_labelled/EP_ZH_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check and remove overlap\n",
    "def overlap_check(df):\n",
    "    df_list = df['response'].tolist()\n",
    "\n",
    "    overlap_index = [index for (index,response) in enumerate(df_list) if response in df_list[index+1:]]\n",
    "    \n",
    "    return overlap_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "# check for overlap\n",
    "EN_overlap = overlap_check(EP_EN)\n",
    "print(len(EN_overlap)) # 79 instances\n",
    "\n",
    "ZH_overlap = overlap_check(EP_ZH)\n",
    "print(len(ZH_overlap)) # 84 instances \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021\n",
      "1016\n"
     ]
    }
   ],
   "source": [
    "# remove overlap\n",
    "EP_EN.drop(labels=EN_overlap, axis=0, inplace=True)\n",
    "EP_ZH.drop(labels=ZH_overlap, axis=0, inplace=True)\n",
    "print(len(EP_EN))\n",
    "print(len(EP_ZH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check - make sure no more overlaps\n",
    "print(len(overlap_check(EP_EN)))\n",
    "print(len(overlap_check(EP_ZH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    35.063663\n",
      "2    34.965720\n",
      "0    29.970617\n",
      "Name: empathy_score, dtype: float64\n",
      "2    35.137795\n",
      "1    35.137795\n",
      "0    29.724409\n",
      "Name: empathy_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check distribution - slightly skewed\n",
    "print(EP_EN['empathy_score'].value_counts(normalize=True)*100) \n",
    "print(EP_ZH['empathy_score'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract from each category\n",
    "def balance_dataset(df):\n",
    "    min_len = min(df['empathy_score'].value_counts())\n",
    "    df_balanced = pd.DataFrame()\n",
    "    for score in range(3):\n",
    "        df_score = df[df['empathy_score']==score]\n",
    "        df_score = df_score.sample(min_len, random_state=0)\n",
    "        df_balanced = pd.concat([df_balanced, df_score])\n",
    "\n",
    "    return df_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    33.333333\n",
      "1    33.333333\n",
      "2    33.333333\n",
      "Name: empathy_score, dtype: float64\n",
      "0    33.333333\n",
      "1    33.333333\n",
      "2    33.333333\n",
      "Name: empathy_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "EN_balanced = balance_dataset(EP_EN)\n",
    "ZH_balanced = balance_dataset(EP_ZH)\n",
    "\n",
    "# Sanity check\n",
    "print(EN_balanced['empathy_score'].value_counts(normalize=True)*100) \n",
    "print(ZH_balanced['empathy_score'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only reponse and empathy score\n",
    "EN_balanced.drop(labels=['annotator1_score','annotator2_score','annotator3_score'], axis=1, inplace=True)\n",
    "ZH_balanced.drop(labels=['annotator1_score','annotator2_score','annotator3_score'], axis=1, inplace=True)\n",
    "\n",
    "# Change headings\n",
    "newlabels = {'response': 'text', \n",
    "            'empathy_score': 'labels'}\n",
    "\n",
    "EN_balanced = EN_balanced.rename(columns = newlabels)\n",
    "ZH_balanced = ZH_balanced.rename(columns = newlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    276\n",
      "1    275\n",
      "0    275\n",
      "Name: labels, dtype: int64\n",
      "0    31\n",
      "1    31\n",
      "2    30\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Train Test Splits\n",
    "# EN 90% Train-10% Test Split\n",
    "EN_train, EN_test = train_test_split(EN_balanced, test_size=0.1, shuffle=True, random_state=0, stratify=EN_balanced['labels'])\n",
    "\n",
    "# Check\n",
    "print(EN_train['labels'].value_counts()) \n",
    "print(EN_test['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    242\n",
      "1    241\n",
      "0    241\n",
      "Name: labels, dtype: int64\n",
      "1    31\n",
      "2    30\n",
      "0    30\n",
      "Name: labels, dtype: int64\n",
      "0    31\n",
      "2    30\n",
      "1    30\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ZH 80% Train - 10% Val - 10% Test Split\n",
    "ZH_train, ZH_test = train_test_split(ZH_balanced, test_size=0.2, shuffle=True, random_state=0, stratify=ZH_balanced['labels'])\n",
    "ZH_val, ZH_test = train_test_split(ZH_test, test_size=0.5, shuffle=True, random_state=0, stratify=ZH_test['labels'])\n",
    "\n",
    "# Check\n",
    "print(ZH_train['labels'].value_counts()) \n",
    "print(ZH_val['labels'].value_counts())\n",
    "print(ZH_test['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    518\n",
      "1    516\n",
      "0    516\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Final Train Set\n",
    "EN_ZH_train = pd.concat([EN_train, ZH_train])\n",
    "EN_ZH_train = EN_ZH_train.sample(frac=1).reset_index(drop=True) # shuffle the dataset\n",
    "\n",
    "# Check\n",
    "print(EN_ZH_train['labels'].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "EN_train.to_csv('EN_labelled/EP_EN_train.csv')\n",
    "EN_test.to_csv('EN_labelled/EP_EN_test.csv')\n",
    "\n",
    "ZH_train.to_csv('ZH_labelled/EP_ZH_train.csv')\n",
    "ZH_val.to_csv('ZH_labelled/EP_ZH_val.csv')\n",
    "ZH_test.to_csv('ZH_labelled/EP_ZH_test.csv')\n",
    "\n",
    "EN_ZH_train.to_csv('EP_train.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Labels to Binary \n",
    "High (label=2) and Low (label = 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary(filename):\n",
    "    empathy = pd.read_csv(f'{filename}.csv', index_col=0)\n",
    "    new_label = []\n",
    "    for label in empathy['labels'].to_list():\n",
    "        if label == 2:\n",
    "            new_label.append(1)\n",
    "        else:\n",
    "            new_label.append(0)\n",
    "\n",
    "    empathy['binary'] = new_label\n",
    "    empathy.to_csv(f'{filename}_binary.csv')\n",
    "\n",
    "convert_to_binary('EP_train')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6affe5b8c4f287722cc202c497c24ade3dd225e8a3881670ad8782202279ca81"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 ('satbot': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

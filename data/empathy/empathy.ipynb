{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EmpatheticPersonas Empathy (Labelled) Dataset (1100 Instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "EP_EN = pd.read_csv('EN/EP_EN_annotated.csv')\n",
    "EP_ZH = pd.read_csv('ZH/EP_ZH_annotated.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check and remove overlap\n",
    "def overlap_check(df):\n",
    "    df_list = df['response'].tolist()\n",
    "\n",
    "    overlap_index = [index for (index,response) in enumerate(df_list) if response in df_list[index+1:]]\n",
    "    \n",
    "    return overlap_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "# check for overlap\n",
    "EN_overlap = overlap_check(EP_EN)\n",
    "print(len(EN_overlap)) # 79 instances\n",
    "\n",
    "ZH_overlap = overlap_check(EP_ZH)\n",
    "print(len(ZH_overlap)) # 84 instances \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021\n",
      "1016\n"
     ]
    }
   ],
   "source": [
    "# remove overlap\n",
    "EP_EN.drop(labels=EN_overlap, axis=0, inplace=True)\n",
    "EP_ZH.drop(labels=ZH_overlap, axis=0, inplace=True)\n",
    "print(len(EP_EN))\n",
    "print(len(EP_ZH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check - make sure no more overlaps\n",
    "print(len(overlap_check(EP_EN)))\n",
    "print(len(overlap_check(EP_ZH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    35.063663\n",
      "2    34.965720\n",
      "0    29.970617\n",
      "Name: empathy_score, dtype: float64\n",
      "2    35.137795\n",
      "1    35.137795\n",
      "0    29.724409\n",
      "Name: empathy_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check distribution - slightly skewed\n",
    "print(EP_EN['empathy_score'].value_counts(normalize=True)*100) \n",
    "print(EP_ZH['empathy_score'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract from each category\n",
    "def balance_dataset(df):\n",
    "    min_len = min(df['empathy_score'].value_counts())\n",
    "    df_balanced = pd.DataFrame()\n",
    "    for score in range(3):\n",
    "        df_score = df[df['empathy_score']==score]\n",
    "        df_score = df_score.sample(min_len, random_state=0)\n",
    "        df_balanced = pd.concat([df_balanced, df_score])\n",
    "\n",
    "    return df_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    33.333333\n",
      "1    33.333333\n",
      "2    33.333333\n",
      "Name: empathy_score, dtype: float64\n",
      "0    33.333333\n",
      "1    33.333333\n",
      "2    33.333333\n",
      "Name: empathy_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "EN_balanced = balance_dataset(EP_EN)\n",
    "ZH_balanced = balance_dataset(EP_ZH)\n",
    "\n",
    "# Sanity check\n",
    "print(EN_balanced['empathy_score'].value_counts(normalize=True)*100) \n",
    "print(ZH_balanced['empathy_score'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only reponse and empathy score\n",
    "EN_balanced.drop(labels=['annotator1_score','annotator2_score','annotator3_score'], axis=1, inplace=True)\n",
    "ZH_balanced.drop(labels=['annotator1_score','annotator2_score','annotator3_score'], axis=1, inplace=True)\n",
    "\n",
    "# Change headings\n",
    "newlabels = {'response': 'text', \n",
    "            'empathy_score': 'labels'}\n",
    "\n",
    "EN_balanced = EN_balanced.rename(columns = newlabels)\n",
    "ZH_balanced = ZH_balanced.rename(columns = newlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    276\n",
      "1    275\n",
      "0    275\n",
      "Name: labels, dtype: int64\n",
      "0    31\n",
      "1    31\n",
      "2    30\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Train Test Splits\n",
    "# EN 90% Train-10% Test Split\n",
    "EN_train, EN_test = train_test_split(EN_balanced, test_size=0.1, shuffle=True, random_state=0, stratify=EN_balanced['labels'])\n",
    "\n",
    "# Check\n",
    "print(EN_train['labels'].value_counts()) \n",
    "print(EN_test['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    242\n",
      "1    241\n",
      "0    241\n",
      "Name: labels, dtype: int64\n",
      "1    31\n",
      "2    30\n",
      "0    30\n",
      "Name: labels, dtype: int64\n",
      "0    31\n",
      "2    30\n",
      "1    30\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ZH 80% Train - 10% Val - 10% Test Split\n",
    "ZH_train, ZH_test = train_test_split(ZH_balanced, test_size=0.2, shuffle=True, random_state=0, stratify=ZH_balanced['labels'])\n",
    "ZH_val, ZH_test = train_test_split(ZH_test, test_size=0.5, shuffle=True, random_state=0, stratify=ZH_test['labels'])\n",
    "\n",
    "# Check\n",
    "print(ZH_train['labels'].value_counts()) \n",
    "print(ZH_val['labels'].value_counts())\n",
    "print(ZH_test['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    518\n",
      "1    516\n",
      "0    516\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Final Train Set\n",
    "EN_ZH_train = pd.concat([EN_train, ZH_train])\n",
    "EN_ZH_train = EN_ZH_train.sample(frac=1).reset_index(drop=True) # shuffle the dataset\n",
    "\n",
    "# Check\n",
    "print(EN_ZH_train['labels'].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "EN_train.to_csv('EN/EP_EN_train.csv')\n",
    "EN_test.to_csv('EN/EP_EN_test.csv')\n",
    "\n",
    "ZH_train.to_csv('ZH/EP_ZH_train.csv')\n",
    "ZH_val.to_csv('ZH/EP_ZH_val.csv')\n",
    "ZH_test.to_csv('ZH/EP_ZH_test.csv')\n",
    "\n",
    "EN_ZH_train.to_csv('EP_empathy_train.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empathetic Rewritings Model Labelled\n",
    "## Extract high empathy sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.read_csv('model_labelled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666\n"
     ]
    }
   ],
   "source": [
    "# find high empathy text\n",
    "high_emp = [index for index,emp_level in enumerate(list(df_model['class'])) if emp_level==2]\n",
    "\n",
    "print(len(high_emp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "焦虑      229\n",
      "所有情绪    178\n",
      "悲伤      125\n",
      "愤怒      107\n",
      "快乐       27\n",
      "Name: emotion, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Anxious         229\n",
       "All emotions    178\n",
       "Sad             125\n",
       "Angry           107\n",
       "Happy            27\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zh = pd.read_csv('EP_empathy_2144_ZH.csv')\n",
    "df_en = pd.read_csv('EP_empathy_2144_EN.csv')\n",
    "\n",
    "# Extract only high empathy sentences\n",
    "high_emp_zh = df_zh.iloc[high_emp]\n",
    "high_emp_en = df_en.iloc[high_emp]\n",
    "\n",
    "high_emp_zh['emotion'].value_counts()\n",
    "high_emp_en['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_emp_zh.to_csv('high_empathy_ZH.csv')\n",
    "high_emp_en.to_csv('high_empathy_EN.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6affe5b8c4f287722cc202c497c24ade3dd225e8a3881670ad8782202279ca81"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 ('satbot': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
